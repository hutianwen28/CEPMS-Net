# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'Main_window.ui'
#
# Created by: PyQt5 UI code generator 5.15.11
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

import argparse
import os
import subprocess
import sys

import numpy as np
import pandas as pd
import torch
import yaml
# from PyQt5.QtWidgets import QMessageBox, QFileDialog, QLineEdit
from PyQt5.QtGui import *
from PyQt5.QtWidgets import *
from PyQt5.QtCore import *
from PyQt5.uic.properties import QtGui
from PyQt5 import QtCore, QtGui, QtWidgets

from mod_untitled import Ui_MainWindow
import cv2
# from matplotlib import pyplot as plt
import matplotlib
matplotlib.use('Agg')  # 使用非交互式后端
from matplotlib import pyplot as plt
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from mediapipe.python.solutions import drawing_utils as mp_drawing
from mediapipe.python.solutions import pose as mp_pose
import io
from PIL import Image

from model import PoseRAC, Action_trigger

from inference_and_visualization_camera import PoseClassificationVisualizer, get_landmarks, normalize_landmarks


class MainWindow(QMainWindow, Ui_MainWindow):
    def __init__(self, parent=None):
        super(MainWindow, self).__init__(parent)
        self.setupUi(self)
        self.CAM_NUM = 0
        self.cap = cv2.VideoCapture()
        # 计时器用于刷新摄像头画面
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_camera_frame)
        self.camera_active = False  # 摄像头状态
        self.background()  # 初始化控件
        self.motion_thread = None # 初始化线程
        self.action_index_mapping = {"front_raise": 0, "pull_up": 1, "squat": 2, "bench_pressing": 3,
                                     "jump_jack": 4, "situp": 5, "push_up": 6, "pommelhorse": 7}  # 抬前臂 抬腿 下蹲 卧推 深蹲跳 仰卧起坐 上推 鞍马
        self.action_map = {"抬前臂": "front_raise", "引体向上": "pull_up", "下蹲": "squat", "卧推": "bench_pressing",
                                     "深蹲跳": "jump_jack", "仰卧起坐": "situp", "俯卧撑": "push_up", "鞍马": "pommelhorse"}
        self.motion = "front_raise" #初始化，后续需要先设置默认值
        self.real_index = 0 # 默认为0
        self.localtion = None #初始化，后续需要先设置默认值

        # 根据新界面新增功能
        self.treeWidget.itemClicked.connect(self.on_tree_item_clicked)
        
        # 初始化曲线图数据
        self.pose_classification_history = []
        self.pose_classification_filtered_history = []
        self.plot_update_counter = 0  # 添加更新计数器，控制更新频率

    def background(self):
        self.pushButton.clicked.connect(self.toggle_camera)

    def toggle_camera(self):
        if self.camera_active:
            self.stop_camera()
        else:
            self.start_camera()
            self.start_motion_detection()

    def stop_camera(self):
        self.stop_motion_detection()  # 停止动作检测线程
        self.timer.stop()
        if self.cap is not None:
            self.cap.release()
            self.cap = None
        # 清除所有显示内容，重置界面状态
        self.label_2.clear()
        self.label_2.setText("摄像头已停止")
        self.label_count.setText("计数: 0")
        self.label_plot.clear()
        self.label_plot.setText("动作置信度曲线")
        
        # 重置数据
        self.pose_classification_history = []
        self.pose_classification_filtered_history = []
        self.plot_update_counter = 0
        
        self.pushButton.setText("开始识别")
        self.camera_active = False

    def start_camera(self):
        self.cap = cv2.VideoCapture(self.CAM_NUM)  # 打开默认摄像头
        if not self.cap.isOpened():
            QMessageBox.warning(self, "警告", "无法打开设备，请检查")
            self.label_2.clear()
            self.label_2.setText("无法打开摄像头")
            return

        # 设置摄像头分辨率，避免过大的视频流
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        self.label_2.setText("摄像头启动中...")
        self.timer.start(30)
        self.pushButton.setText("结束识别")
        self.camera_active = True

    def start_motion_detection(self):
        # 停止原来的摄像头更新计时器，避免冲突
        self.timer.stop()
        
        self.motion_thread = MotionDetectionThread(self.cap, self.real_index, self.motion, self.camera_active)
        # 连接信号
        self.motion_thread.update_plot_data.connect(self.update_plot_display)
        self.motion_thread.update_count.connect(self.update_count_display)
        self.motion_thread.update_frame.connect(self.update_frame_display)
        self.motion_thread.start()

    def stop_motion_detection(self):
        if self.motion_thread:
            print("停止动作检测")
            self.motion_thread.stop()
            self.motion_thread.quit()
            self.motion_thread = None
            
    def update_plot_display(self, pose_classification, pose_classification_filtered):
        """更新曲线图显示"""
        # 添加数据到历史记录
        self.pose_classification_history.append(pose_classification)
        self.pose_classification_filtered_history.append(pose_classification_filtered)
        
        # 限制历史记录长度，避免内存过度使用
        max_history = 200
        if len(self.pose_classification_history) > max_history:
            self.pose_classification_history = self.pose_classification_history[-max_history:]
            self.pose_classification_filtered_history = self.pose_classification_filtered_history[-max_history:]
        
        # 恢复曲线图更新，每5帧更新一次
        self.plot_update_counter += 1
        if self.plot_update_counter % 5 == 0:
            self.plot_classification_history()
    
    def update_count_display(self, count):
        """更新计数显示"""
        self.label_count.setText(f"计数: {count}")
    
    def plot_classification_history(self):
        """绘制分类历史曲线图 - 固定尺寸版本"""
        try:
            # 完全固定的图片尺寸和参数
            fig_width, fig_height = 300, 200  # 固定像素尺寸
            dpi = 100
            
            # 创建固定尺寸的图形
            fig = plt.figure(figsize=(fig_width/dpi, fig_height/dpi), dpi=dpi)
            ax = fig.add_subplot(111)
            ax.clear()
            
            # 如果没有数据，显示空图
            if not self.pose_classification_history:
                ax.text(0.5, 0.5, 'Waiting for data...', 
                       horizontalalignment='center', verticalalignment='center',
                       transform=ax.transAxes)
            else:
                # 绘制两条曲线
                for i, classification_history in enumerate([self.pose_classification_history,
                                           self.pose_classification_filtered_history]):
                    y = []
                    for classification in classification_history:
                        if classification is None:
                            y.append(0)  # 用0替代None，避免绘制问题
                        else:
                            y.append(classification)
                    
                    if y:  # 只有当有数据时才绘制
                        ax.plot(y, linewidth=1.5, alpha=0.8)

                ax.grid(axis='y', alpha=0.5)
                ax.set_ylim(0, 1)
                
                # 限制x轴范围
                if len(self.pose_classification_history) > 200:
                    ax.set_xlim(right=200)
            
            ax.set_xlabel('Frame', fontsize=8)
            ax.set_ylabel('Confidence', fontsize=8)
            ax.set_title(f'{self.motion}', fontsize=9)
            ax.tick_params(labelsize=7)

            buf = io.BytesIO()
            fig.savefig(buf, format='png', dpi=dpi, 
                       facecolor='white', edgecolor='none',
                       bbox_inches=None) 
            buf.seek(0)
            
            # 读取并处理图片
            img = Image.open(buf)
            if img.mode != 'RGB':
                img = img.convert('RGB')
            
            # 强制调整到固定尺寸
            img = img.resize((fig_width, fig_height), Image.LANCZOS)
            
            # 转换为Qt格式
            img_array = np.array(img)
            height, width, channel = img_array.shape
            bytes_per_line = 3 * width
            q_image = QImage(img_array.data, width, height, bytes_per_line, QImage.Format_RGB888)
            
            # 设置到label，保持固定尺寸
            pixmap = QPixmap.fromImage(q_image)
            self.label_plot.setPixmap(pixmap)
            
        except Exception as e:
            print(f"曲线图绘制错误: {e}")
            # 出错时显示错误信息
            self.label_plot.setText(f"曲线图更新错误")
        finally:
            # 确保资源清理
            if 'fig' in locals():
                plt.close(fig)
            if 'buf' in locals():
                buf.close()

    def update_camera_frame(self):
        ret, frame = self.cap.read()
        if ret:
            # 获取 label_2 的宽高
            label_width = self.label_2.width()
            label_height = self.label_2.height()

            # 获取 frame 的宽高
            frame_height, frame_width, _ = frame.shape

            # 计算 label_2 的宽高比
            label_aspect_ratio = label_width / label_height
            frame_aspect_ratio = frame_width / frame_height

            # 根据宽高比对 frame 进行裁剪和缩放
            if frame_aspect_ratio > label_aspect_ratio:
                # 如果 frame 宽高比大于 label_2，则从左右两侧裁剪
                new_width = int(frame_height * label_aspect_ratio)
                crop_x = (frame_width - new_width) // 2
                frame = frame[:, crop_x:crop_x + new_width]
            else:
                # 如果 frame 宽高比小于 label_2，则从上下裁剪
                new_height = int(frame_width / label_aspect_ratio)
                crop_y = (frame_height - new_height) // 2
                frame = frame[crop_y:crop_y + new_height, :]

            # 转换图像格式
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            height, width, channel = frame.shape
            bytes_per_line = 3 * width
            q_image = QImage(frame.data, width, height, bytes_per_line, QImage.Format_RGB888)

            # 缩放图像以适应 label_2 的尺寸
            q_image_scaled = q_image.scaled(self.label_2.size(), QtCore.Qt.KeepAspectRatio)
            pixmap = QPixmap.fromImage(q_image_scaled)

            # 设置摄像头标签图像
            self.label_2.setPixmap(pixmap)

    # 新增的功能函数
    def on_tree_item_clicked(self, item, column):
        # 获取点击的项目名称
        selected_motion = item.text(0)
        # 根据 action_map 获取英文名称
        if selected_motion in self.action_map:
            english_motion = self.action_map[selected_motion]
            self.update_motion(english_motion)
        else:
            print(f"未找到该动作的映射: {selected_motion}")

    # 仅用于调试，后续需要修改
    def update_motion(self, motion):
        if motion in self.action_index_mapping:
            # 更新 real_index 和 motion
            self.real_index = self.action_index_mapping[motion]
            self.motion = motion
            print(f"动作: {motion}, 索引: {self.real_index}")
            
            # 更新界面显示
            action_names = {"front_raise": "抬前臂", "pull_up": "引体向上", "squat": "下蹲", "bench_pressing": "卧推",
                           "jump_jack": "深蹲跳", "situp": "仰卧起坐", "push_up": "俯卧撑", "pommelhorse": "鞍马"}
            chinese_name = action_names.get(motion, motion)
            self.label_current_action.setText(f"当前动作: {chinese_name}")
            
            # 重置曲线图数据
            self.pose_classification_history = []
            self.pose_classification_filtered_history = []
            self.plot_update_counter = 0  # 重置更新计数器
            self.label_count.setText("计数: 0")
            self.label_plot.setText("动作置信度曲线")
            self.label_plot.clear()

            # 如果检测线程已经启动，更新线程中的动作参数
            if self.motion_thread is not None:
                self.motion_thread.real_index = self.real_index
                self.motion_thread.action_type = self.motion
                self.motion_thread.update_action(self.real_index,self.motion)
                print(f"线程中动作更新为: {self.motion}, 索引: {self.real_index}")
        else:
            print(f"未找到该动作的索引映射: {motion}")

    def update_frame_display(self, frame):
        """更新带有人体关键点的视频画面 - 固定尺寸版本"""
        try:
            # 确保frame是正确的格式
            if frame is None or frame.size == 0:
                return
            
            # 设置固定的最大视频显示尺寸，防止界面无限增大
            MAX_VIDEO_WIDTH = 640
            MAX_VIDEO_HEIGHT = 480
            
            # 获取原始帧尺寸
            original_height, original_width, channel = frame.shape
            if channel != 3:
                return
            
            # 计算缩放比例，保持宽高比
            width_ratio = MAX_VIDEO_WIDTH / original_width
            height_ratio = MAX_VIDEO_HEIGHT / original_height
            scale_ratio = min(width_ratio, height_ratio)
            
            # 计算新的尺寸
            new_width = int(original_width * scale_ratio)
            new_height = int(original_height * scale_ratio)
            
            # 使用OpenCV调整图像大小，这比Qt缩放更稳定
            resized_frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_LINEAR)
            
            # 转换为QImage
            height, width, channel = resized_frame.shape
            bytes_per_line = 3 * width
            q_image = QImage(resized_frame.data, width, height, bytes_per_line, QImage.Format_RGB888)
            
            # 直接设置，不再进行Qt缩放
            pixmap = QPixmap.fromImage(q_image)
            self.label_2.setPixmap(pixmap)
            
        except Exception as e:
            print(f"视频显示错误: {e}")

def resource_path(relative_path):
    """ 获取资源文件的绝对路径 """
    try:
        # PyInstaller 创建的临时文件夹
        base_path = sys._MEIPASS
    except Exception:
        # 运行在开发环境下的路径
        base_path = os.path.abspath(".")

    return os.path.join(base_path, relative_path)
class MotionDetectionThread(QThread):
    update_frame = pyqtSignal(np.ndarray)  # 发送视频帧数据
    update_plot_data = pyqtSignal(float, float)  # 发送置信度数据
    update_count = pyqtSignal(int)  # 发送计数数据

    def __init__(self, cap, real_index, action_type, camera_active):
        super().__init__()
        self.cap = cap
        self.real_index = real_index
        self.action_type = action_type
        self.running = True  # 用于控制线程的运行状态
        self.camera_active = camera_active
        self.pose_classification_visualizer = None  # 添加此项，初始化为空
        self.relative_path =''

    def update_action(self, real_index, action_type):
        """用于实时更新动作类型和对应的索引"""
        self.real_index = real_index
        self.action_type = action_type
        # 重置重复计数器和可视化工具
        self.reset_pose_visualizer()

    def reset_pose_visualizer(self):
        """重置折线图和计数"""
        self.pose_classification_visualizer = PoseClassificationVisualizer(
            class_name=self.action_type,  # 使用新的动作名称
            plot_x_max=500,
            plot_y_max=1
        )
        print(f"更新动作: {self.action_type}, real_index: {self.real_index}")


    def run(self):
        # 将 motion_detection 函数中的逻辑放到这里
        # 使用 self.running 控制 while 循环

        print("动作检测线程运行中")
        # csv_label_path = resource_path('all_action_realtime.csv')
        # csv_label_path = '.\\all_action_realtime.csv'
        # root_dir = '..\\RepCount_pose'
        print("进入motion_detection函数")
        # label_pd = pd.read_csv(csv_label_path)
        columns = ['action', 'label']

        # 创建一个包含CSV数据的字典
        data = {
            'action': ['front_raise', 'pull_up', 'squat', 'bench_pressing', 'jump_jack', 'situp', 'push_up',
                       'pommelhorse'],
            'label': [0, 1, 2, 3, 4, 5, 6, 7]
        }

        # 使用字典创建DataFrame
        label_pd = pd.DataFrame(data)
        index2action = {}
        length_label = len(label_pd.index)
        for label_i in range(length_label):
            one_data = label_pd.iloc[label_i]
            action = one_data['action']
            label = one_data['label']
            index2action[label] = action
        num_classes = len(index2action)

        model = PoseRAC(None, None, None, None, dim=99, heads=9,
                        enc_layer=6, learning_rate=0.001,
                        seed=42, num_classes=num_classes, alpha=0.012)
        weight_path = resource_path('.\\best_weights_PoseRAC.pth')
        new_weights = torch.load(weight_path, map_location='cpu')
        model.load_state_dict(new_weights)
        model.eval()
        print("调用PoseRAC模型")
        enter_threshold = 0.78
        exit_threshold = 0.4
        momentum = 0.4
        real_index = self.real_index
        print(real_index)
        action_type = index2action[real_index]

        repetition_salient_1 = Action_trigger(
            action_name=action_type,
            enter_threshold=enter_threshold,
            exit_threshold=exit_threshold
        )
        repetition_salient_2 = Action_trigger(
            action_name=action_type,
            enter_threshold=enter_threshold,
            exit_threshold=exit_threshold
        )
        classify_prob = 0.5
        pose_count = 0
        curr_pose = 'holder'
        init_pose = 'pose_holder'

        # 使用相机
        # if not self.cap.isOpened():
        #     QMessageBox.information(self, "警告", "请检查设备", QMessageBox.Ok)
        #     return
        video_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        video_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

        pose_tracker = mp_pose.Pose()
        pose_classification_visualizer = PoseClassificationVisualizer(
            class_name=action_type,
            plot_x_max=500,
            plot_y_max=1
        )
        frame_idx = 0
        frame_count = 0
        tensors = None

        while True:
            if not self.cap.isOpened() or not self.running:
                break

            success, input_frame = self.cap.read()
            if not success:
                break

            real_index = self.real_index
            action_type = self.action_type

            frame_count += 1
            input_frame = cv2.cvtColor(input_frame, cv2.COLOR_BGR2RGB)
            result = pose_tracker.process(image=input_frame)
            pose_landmarks = result.pose_landmarks

            output_frame = input_frame.copy()
            if pose_landmarks is not None:
                mp_drawing.draw_landmarks(image=output_frame, landmark_list=pose_landmarks,
                                          connections=mp_pose.POSE_CONNECTIONS)
            else:
                continue

            landmarks = get_landmarks(pose_landmarks)
            normalized_landmarks = normalize_landmarks(landmarks)
            normalized_landmarks = normalized_landmarks[0].reshape(-1, 99)
            tensor = torch.from_numpy(normalized_landmarks).float()

            if tensors is None:
                tensors = tensor
            else:
                if tensors.shape[0] == 100:
                    tensors = tensor[1:]
                tensors = torch.cat((tensors, tensor), 0)

            if tensors.shape[0] < 30:
                continue

            output = torch.sigmoid(model(tensors))[-1]
            output_numpy = output[real_index].detach().cpu().numpy()
            classify_prob = output_numpy * (1 - momentum) + momentum * classify_prob

            salient1_triggered = repetition_salient_1(classify_prob)
            reverse_classify_prob = 1 - classify_prob
            salient2_triggered = repetition_salient_2(reverse_classify_prob)

            if init_pose == 'pose_holder':
                if salient1_triggered:
                    init_pose = 'salient1'
                elif salient2_triggered:
                    init_pose = 'salient2'

            if init_pose == 'salinet1':
                if curr_pose == 'salient1' and salient2_triggered:
                    pose_count += 1
            else:
                if curr_pose == 'salient2' and salient1_triggered:
                    pose_count += 1

            if salient1_triggered:
                curr_pose = 'salient1'
            elif salient2_triggered:
                curr_pose = 'salient2'

            # 发送曲线图数据和计数数据到主界面
            self.update_plot_data.emit(classify_prob, classify_prob)
            self.update_count.emit(pose_count)

            # 发送带有人体关键点的视频帧数据到主界面
            self.update_frame.emit(output_frame)

    def stop(self):
        print("调用stop方法")
        self.running = False  # 设置 running 为 False 以停止线程
        self.quit()
        self.wait()

if __name__ == "__main__":
    QtCore.QCoreApplication.setAttribute(QtCore.Qt.AA_EnableHighDpiScaling)
    app = QApplication(sys.argv)
    player = MainWindow()
    player.show()
    sys.exit(app.exec_())
